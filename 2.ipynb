{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ARMA 過程\n",
    "## 2.1 ARMA 過程の性質\n",
    "時系列データの基本となる自己回帰移動平均(ARMA: auto regressive moving average)モデルについて。ARMA 過程は AR 過程と MA 過程を組み合わせたモデル。\n",
    "\n",
    "例えば1次の自己相関を持つ時系列データをモデル化することを考える。ひとつの方法は $y_t$ と $y_{t-1}$ のモデルに共通の成分を含ませるというもの。具体的には、\n",
    "$$y_t = a + b$$\n",
    "$$y_{t-1} = c + b$$\n",
    "というモデル化を行えば、共通の $b$ によって $y_t$ と $y_{t-1}$ が相関を持つことをモデル化できる。これが MA モデル。\n",
    "\n",
    "もうひとつの方法はもっと直接的で、 $y_t$ のモデルに $y_{t-1}$ を含めるもの。具体的には以下。\n",
    "$$y_t = ay_{t-1} + b$$\n",
    "これが AR モデルである。\n",
    "\n",
    "## 2.1.1 MA 過程\n",
    "MA 過程はホワイトノイズの線形和で表される。1次の MA 過程のモデル(MA(1) と表記)は以下。\n",
    "$$y_t = \\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}$$\n",
    "$$\\epsilon_t \\sim W.N.(\\sigma^2)$$\n",
    "$y_{t-1}$ のデータを作るときに使った $\\epsilon_{t-1}$ の値を、重み $\\theta_1$ をかけた上で加算している。$\\epsilon$ は撹乱項と呼ばれる。\n",
    "\n",
    "### MA 過程の期待値\n",
    "$$E(y_t) = E(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}) = E(\\mu) + E(\\epsilon_t) + E(\\theta_1\\epsilon_{t-1}) = \\mu$$\n",
    "$\\epsilon$ はホワイトノイズなので、期待値は 0 であるため。\n",
    "\n",
    "よって MA 過程の期待値は $\\mu$ である。\n",
    "\n",
    "### MA 過程の分散\n",
    "$$\\gamma_0 = \\mbox{Var}(y_t) = \\mbox{Var}(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "a が定数の時、$\\mbox{Var}(X + a) = \\mbox{Var}(X)$ なので\n",
    "\n",
    "$$\\mbox{Var}(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}) = \\mbox{Var}(\\epsilon_t + \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "分散について $\\mbox{Var}(X,Y) = V(X) + V(Y) + 2\\mbox{Cov}(X,Y)$ である。よって\n",
    "\n",
    "$$\\mbox{Var}(\\epsilon_t + \\theta_1\\epsilon_{t-1}) = \\mbox{Var}(\\epsilon_t) + \\mbox{Var}(\\theta_1\\epsilon_{t-1}) + 2\\mbox{Cov}(\\epsilon_t, \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "さらに分散について、a が定数の時 $\\mbox{Var}(aX) = a^2\\mbox{Var}(X)$ である。よって\n",
    "\n",
    "$$\\mbox{Var}(\\epsilon_t) + \\mbox{Var}(\\theta_{t-1}\\epsilon_{t-1}) + 2\\mbox{Cov}(\\epsilon_t, \\theta_{t-1}\\epsilon_{t-1}) = \\mbox{Var}(\\epsilon_t) + \\theta_1^2\\mbox{Var}(\\epsilon_{t-1}) + 2\\mbox{Cov}(\\epsilon_t, \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "共分散について、$\\mbox{Cov}(X,Y) = E((X - \\overline{X})(Y - \\overline{Y}))$ なので、$\\mbox{Cov}(\\epsilon_t, \\theta_1\\epsilon_{t-1}) = E((\\epsilon_t - \\overline{\\epsilon_t})(\\theta_1\\epsilon_{t-1} - \\overline{\\theta_1\\epsilon_{t-1}})) = \\theta_1E((\\epsilon_t - \\overline{\\epsilon_t})(\\epsilon_{t-1} - \\overline{\\epsilon_{t-1}})) = \\theta_1\\mbox{Cov}(\\epsilon_t, \\theta_1\\epsilon_{t-1})$ である。よって\n",
    "\n",
    "$$\\mbox{Var}(\\epsilon_t) + \\theta_1^2\\mbox{Var}(\\epsilon_{t-1}) + 2\\mbox{Cov}(\\epsilon_t, \\theta_1\\epsilon_{t-1}) = \\mbox{Var}(\\epsilon_t) + \\theta_1^2\\mbox{Var}(\\epsilon_{t-1}) + 2\\theta_1\\mbox{Cov}(\\epsilon_t, \\epsilon_{t-1})$$\n",
    "\n",
    "ここで $\\epsilon$ はホワイトノイズなので $\\mbox{Cov}(\\epsilon_t, \\epsilon_{t-1}) = 0$ である。よって\n",
    "\n",
    "$$\\mbox{Var}(\\epsilon_t) + \\theta_1^2\\mbox{Var}(\\epsilon_{t-1}) + 2\\theta_1\\mbox{Cov}(\\epsilon_t, \\epsilon_{t-1}) = \\mbox{Var}(\\epsilon_t) + \\theta_1^2\\mbox{Var}(\\epsilon_{t-1})$$\n",
    "\n",
    "$\\mbox{Var}(\\epsilon) = \\sigma^2$ なので\n",
    "\n",
    "$$\\mbox{Var}(\\epsilon_t) + \\theta_1^2\\mbox{Var}(\\epsilon_{t-1}) = (1 + \\theta_1^2)\\sigma^2$$\n",
    "\n",
    "よって MA(1) 過程の分散 $\\gamma_0$ は $(1 + \\theta_1^2)\\sigma^2$ である。元々の分散 $\\sigma^2$ よりも少し大きくなる。\n",
    "\n",
    "### 用語：\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
