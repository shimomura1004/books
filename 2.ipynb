{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ARMA 過程\n",
    "## 2.1 ARMA 過程の性質\n",
    "時系列データの基本となる自己回帰移動平均(ARMA: auto regressive moving average)モデルについて。ARMA 過程は AR 過程と MA 過程を組み合わせたモデル。\n",
    "\n",
    "例えば1次の自己相関を持つ時系列データをモデル化することを考える。ひとつの方法は $y_t$ と $y_{t-1}$ のモデルに共通の成分を含ませるというもの。具体的には、\n",
    "$$y_t = a + b$$\n",
    "$$y_{t-1} = c + b$$\n",
    "というモデル化を行えば、共通の $b$ によって $y_t$ と $y_{t-1}$ が相関を持つことをモデル化できる。これが MA モデル。\n",
    "\n",
    "もうひとつの方法はもっと直接的で、 $y_t$ のモデルに $y_{t-1}$ を含めるもの。具体的には以下。\n",
    "$$y_t = ay_{t-1} + b$$\n",
    "これが AR モデルである。\n",
    "\n",
    "## 2.1.1 MA 過程\n",
    "MA 過程はホワイトノイズの線形和で表される。1次の MA 過程のモデル(MA(1) と表記)は以下。\n",
    "$$y_t = \\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}$$\n",
    "$$\\epsilon_t \\sim W.N.(\\sigma^2)$$\n",
    "$y_{t-1}$ のデータを作るときに使った $\\epsilon_{t-1}$ の値を、重み $\\theta_1$ をかけた上で加算している。$\\epsilon$ は撹乱項と呼ばれる。\n",
    "\n",
    "### MA 過程の期待値\n",
    "$$E(y_t)\n",
    "= E(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1})\n",
    "= E(\\mu) + E(\\epsilon_t) + E(\\theta_1\\epsilon_{t-1})\n",
    "= \\mu$$\n",
    "$\\epsilon$ はホワイトノイズなので、期待値は 0 であるため。\n",
    "\n",
    "よって MA 過程の期待値は $\\mu$ である。\n",
    "\n",
    "### MA 過程の分散\n",
    "$$\\gamma_0\n",
    "= Var(y_t)\n",
    "= Var(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "a が定数の時、$Var(X + a) = Var(X)$ なので\n",
    "\n",
    "$$Var(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1})\n",
    "= Var(\\epsilon_t + \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "分散について $Var(X,Y) = V(X) + V(Y) + 2Cov(X,Y)$ である。よって\n",
    "\n",
    "$$Var(\\epsilon_t + \\theta_1\\epsilon_{t-1})\n",
    "= Var(\\epsilon_t) + Var(\\theta_1\\epsilon_{t-1}) + 2Cov(\\epsilon_t, \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "さらに分散について、a が定数の時 $Var(aX) = a^2Var(X)$ である。よって\n",
    "\n",
    "$$Var(\\epsilon_t) + Var(\\theta_{t-1}\\epsilon_{t-1}) + 2Cov(\\epsilon_t, \\theta_{t-1}\\epsilon_{t-1})\n",
    "= Var(\\epsilon_t) + \\theta_1^2Var(\\epsilon_{t-1}) + 2Cov(\\epsilon_t, \\theta_1\\epsilon_{t-1})$$\n",
    "\n",
    "共分散について、$Cov(X,Y) = E((X - \\overline{X})(Y - \\overline{Y}))$ なので、$Cov(\\epsilon_t, \\theta_1\\epsilon_{t-1}) = E((\\epsilon_t - \\overline{\\epsilon_t})(\\theta_1\\epsilon_{t-1} - \\overline{\\theta_1\\epsilon_{t-1}})) = \\theta_1E((\\epsilon_t - \\overline{\\epsilon_t})(\\epsilon_{t-1} - \\overline{\\epsilon_{t-1}})) = \\theta_1Cov(\\epsilon_t, \\theta_1\\epsilon_{t-1})$ である。よって\n",
    "\n",
    "$$Var(\\epsilon_t) + \\theta_1^2Var(\\epsilon_{t-1}) + 2Cov(\\epsilon_t, \\theta_1\\epsilon_{t-1})\n",
    "= Var(\\epsilon_t) + \\theta_1^2Var(\\epsilon_{t-1}) + 2\\theta_1Cov(\\epsilon_t, \\epsilon_{t-1})$$\n",
    "\n",
    "ここで $\\epsilon$ はホワイトノイズなので $Cov(\\epsilon_t, \\epsilon_{t-1}) = 0$ である。よって\n",
    "\n",
    "$$Var(\\epsilon_t) + \\theta_1^2Var(\\epsilon_{t-1}) + 2\\theta_1Cov(\\epsilon_t, \\epsilon_{t-1})\n",
    "= Var(\\epsilon_t) + \\theta_1^2Var(\\epsilon_{t-1})$$\n",
    "\n",
    "$Var(\\epsilon) = \\sigma^2$ なので\n",
    "\n",
    "$$Var(\\epsilon_t) + \\theta_1^2Var(\\epsilon_{t-1})\n",
    "= (1 + \\theta_1^2)\\sigma^2$$\n",
    "\n",
    "よって MA(1) 過程の分散 $\\gamma_0$ は $(1 + \\theta_1^2)\\sigma^2$ である。元々の分散 $\\sigma^2$ よりも少し大きくなる。\n",
    "\n",
    "*参考: https://mathtrain.jp/exvarcov*\n",
    "\n",
    "### MA 過程の自己相関\n",
    "MA 過程では $\\theta$ の大きさによって自己相関が変化する。$\\theta$ が大きくなると過去の値と同じような値を取る確率が高くなっていくので、$\\theta$ が大きくなると自己相関も大きくなるはず。MA(1) 過程の自己相関を具体的に計算してみる。まず1次の自己共分散は\n",
    "\n",
    "$$\\gamma_1 = Cov(y_t, y_{t-1})\n",
    "= Cov(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}, \\mu + \\epsilon_{t-1} + \\theta_1\\epsilon_{t-2})$$\n",
    "\n",
    "共分散について、$Cov(X,Y) = E((X - \\overline{X})(Y - \\overline{Y}))$ なので、\n",
    "\n",
    "$$Cov(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}, \\mu + \\epsilon_{t-1} + \\theta_1\\epsilon_{t-2})\n",
    "= E((\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1} - \\overline{(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1})})(\\mu + \\epsilon_{t-1} + \\theta_1\\epsilon_{t-2} - \\overline{(\\mu + \\epsilon_{t-1} + \\theta_1\\epsilon_{t-2})}))\n",
    "= E((\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1} - \\mu)(\\mu + \\epsilon_{t-1} + \\theta_1\\epsilon_{t-2} - \\mu))\n",
    "= E((\\epsilon_t + \\theta_1\\epsilon_{t-1})(\\epsilon_{t-1} + \\theta_1\\epsilon_{t-2}))\n",
    "= E(\\epsilon_t \\epsilon_{t-1} + \\epsilon_t \\theta_1\\epsilon_{t-2} + \\theta_1\\epsilon_{t-1} \\epsilon_{t-1} + \\theta_1\\epsilon_{t-1} \\theta_1\\epsilon_{t-2})\n",
    "= E(\\epsilon_t \\epsilon_{t-1} + \\theta_1\\epsilon_t\\epsilon_{t-2} + \\theta_1\\epsilon_{t-1}^2 + \\theta_1^2\\epsilon_{t-1} \\epsilon_{t-2})\n",
    "= E(\\epsilon_t \\epsilon_{t-1}) + E(\\theta_1\\epsilon_t\\epsilon_{t-2}) + E(\\theta_1\\epsilon_{t-1}^2) + E(\\theta_1^2\\epsilon_{t-1} \\epsilon_{t-2})\n",
    "$$\n",
    "\n",
    "ここで $\\epsilon$ がホワイトノイズの場合、$\\gamma_k = E(\\epsilon_t\\epsilon_{t-k})$ は $k = 0$ のとき $\\sigma^2$、 $k \\neq 0$ のとき $0$ である。よって\n",
    "\n",
    "$$E(\\epsilon_t \\epsilon_{t-1}) + E(\\theta_1\\epsilon_t\\epsilon_{t-2}) + E(\\theta_1\\epsilon_{t-1}^2) + E(\\theta_1^2\\epsilon_{t-1} \\epsilon_{t-2})\n",
    "= E(\\theta_1\\epsilon_{t-1}^2)\n",
    "= \\theta_1 E(\\epsilon_{t-1}^2)\n",
    "= \\theta_1 \\sigma^2\n",
    "$$\n",
    "\n",
    "この結果、MA(1)過程の1次自己共分散 $\\gamma_1 = \\theta_1 \\sigma^2$ である。1次の自己相関は\n",
    "\n",
    "$$\\rho\n",
    "= \\frac{\\gamma_1}{\\gamma_0}\n",
    "= \\frac{\\theta_1 \\sigma^2}{(1 + \\theta_1^2)\\sigma^2}\n",
    "= \\frac{\\theta_1}{1 + \\theta_1^2}\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "### MA(1) 過程の2次以降の自己相関\n",
    "$$\\gamma_k\n",
    "= Cov(y_t, t_{t-k})\n",
    "= Cov(\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}, \\mu + \\epsilon_{t-k} + \\theta_1\\epsilon_{t-k})\n",
    "= E((\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1} - (\\overline{\\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1}}))(\\mu + \\epsilon_{t-k} + \\theta_1\\epsilon_{t-k} - (\\overline{\\mu + \\epsilon_{t-k} + \\theta_1\\epsilon_{t-k}})))\n",
    "= E((\\epsilon_t + \\theta_1\\epsilon_{t-1})(\\epsilon_{t-k} + \\theta_1\\epsilon_{t-k}))\n",
    "= E(\\epsilon_t\\epsilon_{t-k} + \\epsilon_t\\theta_1\\epsilon_{t-k} + \\theta_1\\epsilon_{t-1}\\epsilon_{t-k} + \\theta_1\\epsilon_{t-1}\\theta_1\\epsilon_{t-k})\n",
    "= E(\\epsilon_t\\epsilon_{t-k}) + E(\\epsilon_t\\theta_1\\epsilon_{t-k}) + E(\\theta_1\\epsilon_{t-1}\\epsilon_{t-k}) + E(\\theta_1\\epsilon_{t-1}\\theta_1\\epsilon_{t-k})\n",
    "$$\n",
    "\n",
    "$k \\geqq 2$ なので、$\\epsilon_t\\epsilon_{t-k}$ と $\\epsilon_{t-1}\\epsilon_{t-k}$ はすべて 0 になる。\n",
    "\n",
    "よって $\\gamma_k = Cov(y_t, y_{t-k}) = 0$ である。\n",
    "\n",
    "### MA 過程の定常性\n",
    "以上の結果より、過程の期待値と自己共分散は時刻 t に依存しない(時刻の差 k にのみ依存する)ことがわかるので、MA(1) 過程は(パラメータの値に関わらず)定常である。\n",
    "\n",
    "### MA(q) 過程とその性質\n",
    "MA(1) 過程を自然に拡張し、MA(q) 過程を考える。式は以下。\n",
    "\n",
    "$$y_t = \\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1} + \\theta_2\\epsilon_{t-2} + \\cdots + \\theta_q\\epsilon_{t-q}, \\epsilon \\sim W.N.(\\sigma^2)$$\n",
    "\n",
    "MA(1) と同じように、以下の性質が成り立つ。\n",
    "\n",
    "#### 平均\n",
    "$$E(y_t) = \\mu$$\n",
    "\n",
    "#### 分散\n",
    "$$\\gamma_0 = Var(y_t) = (1 + \\theta_1^2 + \\theta_2^2 + \\cdots + \\theta_q^2)\\sigma^2$$\n",
    "\n",
    "#### 自己共分散\n",
    "- $1 \\leq k \\leq q $ のとき $$\\gamma_k = (\\theta_k + \\theta_1\\theta_{k+1} + \\cdots \\theta_{q-k}\\theta_q)\\sigma^2$$\n",
    "- $k \\geq q + 1$ のとき $$0$$\n",
    "\n",
    "#### 定常性\n",
    "MA 過程は常に定常である\n",
    "\n",
    "#### 自己相関\n",
    "- $1 \\leq k \\leq q $ のとき $$\\rho_k = \\frac{\\theta_k + \\theta_1\\theta_{k+1} + \\cdots + \\theta_{q-k}\\theta_q}{1 + \\theta_1^2 + \\theta_2^2 + \\cdots + \\theta_q^2}$$\n",
    "- $k \\geq q + 1$ のとき $$0$$\n",
    "\n",
    "MA(q) 過程の q+ 1 次以降の自己相関は 0 になる。モデル化したい時系列データが MA 過程か AR 過程かを判定するときにヒントになる性質。\n",
    "\n",
    "## 2.1.2 AR 過程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
