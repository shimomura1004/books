# 2.識別規則と学習法の概要
## 2.1 識別規則と学習法の分類
- 識別規則とは、入力データ x からクラス C への写像である
- 識別規則の代表例
  - 事後確率によるもの: 事後確率が最大となる(データが得られたとき、その確率が最大になる)クラスに分類する
  - 距離によるもの: 各クラスを代表するベクトルを用意して、データが一番近いベクトルのクラスに分類する
  - 関数値によるもの: 識別関数にデータを適用し、戻り値の正負や最大値でクラスに分類する
  - 決定木によるもの: 識別規則の真偽に応じて次々に識別規則を適用し、分類する
- 教師データが2値で与えられる場合は識別問題、連続値で与えられる場合は回帰と呼ばれる

## 2.2 汎化能力
- 未知のデータに対する識別能力を汎化能力という
- 普通、学習は母集団から一定数をサンプリングした標本に対して行われる
  - 母集団の分布を真の分布といい、真の分布に従うデータで学習し、真の分布に従うデータでテストした結果を真の誤り率という
  - (真の分布と同じとは限らない)標本で学習し、同じデータでテストした結果を再代入誤り率という(学習データとテストデータがまったく同じ)
  - データを学習用とテスト用に分割する方法はいくつかある
    - ホールドアウト法: データを単純に学習用とテスト用にわける。片方を増やすともう一方が減るので、データが大量にあるときに使う。
    - 交差確認法: データを n 個のグループにわけ、1つをテスト用、他を学習用として使う。これを n 回繰り返す。n 分割時に偏りが発生することがあるので、このステップを何度か繰り返す。
    - ブートストラップ法: 再代入誤り率は、学習データとテストデータが同じなので、誤り率が低くなる(バイアス)。n 個のデータから n 回の復元抽出を行って得たデータをブートストラップサンプルという。ブートストラップサンプルを最低でも50回以上作成してバイアスの期待値を求めると、再代入誤り率の誤り率を補正できる。
- 誤り率を下げるためには、学習データを増やすほかに、モデルを変える方法がある
  - 関数近似の場合は、たとえば n 次式に近似する場合に n をいくつにするか決めることをモデルの選択という
  - 複雑なモデルを選択するほうがバイアス(「学習データに対する」予測と実際の差)を小さくできる
  - 複雑なモデルのほうがノイズに追従しやすく、過学習になる。ノイズはランダムなので、近似を複数回行うと結果の分散が大きくなる。
- モデルの MSE(2乗平均誤差)を変形すると、バイアスの2乗と分散の2乗の和で表される
  - この2つがバランスするところが最適な点といえる
